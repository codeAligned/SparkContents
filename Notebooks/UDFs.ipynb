{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Spark by creating a Spark session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"UDFs\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(\n",
    "    [(\"a\", 1, 0), (\"a\", -1, 42), (\"b\", 3, -1), (\"b\", 10, -2)],\n",
    "    (\"key\", \"value1\", \"value2\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"key\", StringType()),\n",
    "    StructField(\"avg_min\", DoubleType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+\n",
      "|key|value1|value2|\n",
      "+---+------+------+\n",
      "|  a|     1|     0|\n",
      "|  a|    -1|    42|\n",
      "|  b|     3|    -1|\n",
      "|  b|    10|    -2|\n",
      "+---+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "from pyspark.sql.functions import PandasUDFType\n",
    "\n",
    "@pandas_udf(schema, functionType=PandasUDFType.GROUPED_MAP)\n",
    "def g(df):\n",
    "    result = pd.DataFrame(df.groupby(df.key).apply(\n",
    "        lambda x: x.loc[:, [\"value1\", \"value2\"]].min(axis=1).mean()\n",
    "    ))\n",
    "    result.reset_index(inplace=True, drop=False)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "|key|avg_min|\n",
      "+---+-------+\n",
      "|  b|   -1.5|\n",
      "|  a|   -0.5|\n",
      "+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby(\"key\").apply(g).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+\n",
      "|key|value1|value2|\n",
      "+---+------+------+\n",
      "|  a|     1|     0|\n",
      "|  a|    -1|    42|\n",
      "|  b|     3|    -1|\n",
      "|  b|    10|    -2|\n",
      "+---+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import pandas_udf,PandasUDFType\n",
    "\n",
    "df3 = spark.createDataFrame(\n",
    "[(\"a\", 1, 0), (\"a\", -1, 42), (\"b\", 3, -1), (\"b\", 10, -2)],\n",
    "(\"key\", \"value1\", \"value2\")\n",
    ")\n",
    "\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------+-------+-------+\n",
      "|key|avg_value1|avg_value2|sum_avg|sub_avg|\n",
      "+---+----------+----------+-------+-------+\n",
      "|  b|       6.5|      -1.5|    5.0|    8.0|\n",
      "|  a|       0.0|      21.0|   21.0|  -21.0|\n",
      "+---+----------+----------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"key\", StringType()),\n",
    "    StructField(\"avg_value1\", DoubleType()),\n",
    "    StructField(\"avg_value2\", DoubleType()),\n",
    "    StructField(\"sum_avg\", DoubleType()),\n",
    "    StructField(\"sub_avg\", DoubleType())\n",
    "])\n",
    "\n",
    "@pandas_udf(schema, functionType=PandasUDFType.GROUPED_MAP)\n",
    "def g(df):\n",
    "    gr = df['key'].iloc[0]\n",
    "    x = df.value1.mean()\n",
    "    y = df.value2.mean()\n",
    "    w = df.value1.mean() + df.value2.mean()\n",
    "    z = df.value1.mean() - df.value2.mean()\n",
    "    return pd.DataFrame([[gr]+[x]+[y]+[w]+[z]])\n",
    "\n",
    "df3.groupby(\"key\").apply(g).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| id|   v|\n",
      "+---+----+\n",
      "|  1| 1.0|\n",
      "|  1| 2.0|\n",
      "|  2| 3.0|\n",
      "|  2| 5.0|\n",
      "|  2|10.0|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "df = spark.createDataFrame([(1, 1.0), (1, 2.0), (2, 3.0), (2, 5.0), (2, 10.0)],(\"id\", \"v\"))\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| id|   v|\n",
      "+---+----+\n",
      "|  1| 2.0|\n",
      "|  1| 2.0|\n",
      "|  2|10.0|\n",
      "|  2|10.0|\n",
      "|  2|10.0|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@pandas_udf(\"id long, v double\", PandasUDFType.GROUPED_MAP)  \n",
    "def normalize(pdf):\n",
    "    v = pdf.v\n",
    "    return pdf.assign(v=v.max())\n",
    "\n",
    "df.groupby(\"id\").apply(normalize).show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

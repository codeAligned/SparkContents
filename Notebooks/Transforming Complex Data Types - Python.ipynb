{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming Complex Data Types in Spark SQL\n",
    "\n",
    "In this notebook we're going to go through some data transformation examples using Spark SQL. Spark SQL supports many\n",
    "built-in transformation functions in the module `pyspark.sql.functions` therefore we will start off by importing that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"ComplexDataTypes\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Convenience function for turning JSON strings into DataFrames.\n",
    "def jsonToDataFrame(json, schema=None):\n",
    "  # SparkSessions are available with Spark 2.0+\n",
    "  reader = spark.read\n",
    "  if schema:\n",
    "    reader.schema(schema)\n",
    "  return reader.json(sc.parallelize([json]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Selecting from nested columns</b> - Dots (`\".\"`) can be used to access nested columns for structs and maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|  b|\n",
      "+---+\n",
      "|  1|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using a struct\n",
    "schema = StructType().add(\"a\", StructType().add(\"b\", IntegerType()))\n",
    "                          \n",
    "events = jsonToDataFrame(\"\"\"\n",
    "{\n",
    "  \"a\": {\n",
    "     \"b\": 1\n",
    "  }\n",
    "}\n",
    "\"\"\", schema)\n",
    "\n",
    "events.select(\"a.b\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|  b|\n",
      "+---+\n",
      "|  1|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using a map\n",
    "schema = StructType().add(\"a\", MapType(StringType(), IntegerType()))\n",
    "                          \n",
    "events = jsonToDataFrame(\"\"\"\n",
    "{\n",
    "  \"a\": {\n",
    "     \"b\": 1\n",
    "  }\n",
    "}\n",
    "\"\"\", schema)\n",
    "\n",
    "events.select(\"a.b\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Flattening structs</b> - A star (`\"*\"`) can be used to select all of the subfields in a struct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "|  b|  c|\n",
      "+---+---+\n",
      "|  1|  2|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "events = jsonToDataFrame(\"\"\"\n",
    "{\n",
    "  \"a\": {\n",
    "     \"b\": 1,\n",
    "     \"c\": 2\n",
    "  }\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "events.select(\"a.*\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Nesting columns</b> - The `struct()` function or just parentheses in SQL can be used to create a new struct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|  x|\n",
      "+---+\n",
      "|[1]|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "events = jsonToDataFrame(\"\"\"\n",
    "{\n",
    "  \"a\": 1,\n",
    "  \"b\": 2,\n",
    "  \"c\": 3\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "events.select(struct(col(\"a\").alias(\"y\")).alias(\"x\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Nesting all columns</b> - The star (`\"*\"`) can also be used to include all columns in a nested struct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|     x|\n",
      "+------+\n",
      "|[1, 2]|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "events = jsonToDataFrame(\"\"\"\n",
    "{\n",
    "  \"a\": 1,\n",
    "  \"b\": 2\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "events.select(struct(\"*\").alias(\"x\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Selecting a single array or map element</b> - `getItem()` or square brackets (i.e. `[ ]`) can be used to select a single element out of an array or a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|  x|\n",
      "+---+\n",
      "|  1|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "events = jsonToDataFrame(\"\"\"\n",
    "{\n",
    "  \"a\": [1, 2]\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "events.select(col(\"a\").getItem(0).alias(\"x\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|  x|\n",
      "+---+\n",
      "|  1|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using a map\n",
    "schema = StructType().add(\"a\", MapType(StringType(), IntegerType()))\n",
    "\n",
    "events = jsonToDataFrame(\"\"\"\n",
    "{\n",
    "  \"a\": {\n",
    "    \"b\": 1\n",
    "  }\n",
    "}\n",
    "\"\"\", schema)\n",
    "\n",
    "events.select(col(\"a\").getItem(\"b\").alias(\"x\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Creating a row for each array or map element</b> - `explode()` can be used to create a new row for each element in an array or each key-value pair.  This is similar to `LATERAL VIEW EXPLODE` in HiveQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|  x|\n",
      "+---+\n",
      "|  1|\n",
      "|  2|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "events = jsonToDataFrame(\"\"\"\n",
    "{\n",
    "  \"a\": [1, 2]\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "events.select(explode(\"a\").alias(\"x\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "|  x|  y|\n",
      "+---+---+\n",
      "|  b|  1|\n",
      "|  c|  2|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using a map\n",
    "schema = StructType().add(\"a\", MapType(StringType(), IntegerType()))\n",
    "\n",
    "events = jsonToDataFrame(\"\"\"\n",
    "{\n",
    "  \"a\": {\n",
    "    \"b\": 1,\n",
    "    \"c\": 2\n",
    "  }\n",
    "}\n",
    "\"\"\", schema)\n",
    "\n",
    "events.select(explode(\"a\").alias(\"x\", \"y\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Collecting multiple rows into an array</b> - `collect_list()` and `collect_set()` can be used to aggregate items into an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|     x|\n",
      "+------+\n",
      "|[1, 2]|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "events = jsonToDataFrame(\"\"\"\n",
    "[{ \"x\": 1 }, { \"x\": 2 }]\n",
    "\"\"\")\n",
    "\n",
    "events.select(collect_list(\"x\").alias(\"x\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "|  y|     x|\n",
      "+---+------+\n",
      "|  b|   [2]|\n",
      "|  a|[1, 3]|\n",
      "+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using an aggregation\n",
    "events = jsonToDataFrame(\"\"\"\n",
    "[{ \"x\": 1, \"y\": \"a\" }, { \"x\": 2, \"y\": \"b\" },{ \"x\": 3, \"y\": \"a\" }]\n",
    "\"\"\")\n",
    "\n",
    "events.groupBy(\"y\").agg(collect_list(\"x\").alias(\"x\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Selecting one field from each item in an array</b> - when you use dot notation on an array we return a new array where that field has been selected from each array element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|     b|\n",
      "+------+\n",
      "|[1, 2]|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "events = jsonToDataFrame(\"\"\"\n",
    "{\n",
    "  \"a\": [\n",
    "    {\"b\": 1},\n",
    "    {\"b\": 2}\n",
    "  ]\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "events.select(\"a.b\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Convert a group of columns to json</b> - `to_json()` can be used to turn structs into json strings. This method is particularly useful when you would like to re-encode multiple columns into a single one when writing data out to Kafka. This method is not presently available in SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|      c|\n",
      "+-------+\n",
      "|{\"b\":1}|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "events = jsonToDataFrame(\"\"\"\n",
    "{\n",
    "  \"a\": {\n",
    "    \"b\": 1\n",
    "  }\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "events.select(to_json(\"a\").alias(\"c\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Parse a column containing json</b> - `from_json()` can be used to turn a string column with json data into a struct. Then you may flatten the struct as described above to have individual columns. This method is not presently available in SQL. \n",
    "**This method is available since Spark 2.1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|  c|\n",
      "+---+\n",
      "|[1]|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "events = jsonToDataFrame(\"\"\"\n",
    "{\n",
    "  \"a\": \"{\\\\\"b\\\\\":1}\"\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "schema = StructType().add(\"b\", IntegerType())\n",
    "events.select(from_json(\"a\", schema).alias(\"c\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes you may want to leave a part of the JSON string still as JSON to avoid too much complexity in your schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|             c|\n",
      "+--------------+\n",
      "|[[1, {\"z\":2}]]|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "events = jsonToDataFrame(\"\"\"\n",
    "{\n",
    "  \"a\": \"{\\\\\"b\\\\\":{\\\\\"x\\\\\":1,\\\\\"y\\\\\":{\\\\\"z\\\\\":2}}}\"\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "schema = StructType().add(\"b\", StructType().add(\"x\", IntegerType())\n",
    "                            .add(\"y\", StringType()))\n",
    "events.select(from_json(\"a\", schema).alias(\"c\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Parse a set of fields from a column containing json</b> - `json_tuple()` can be used to extract a fields available in a string column with json data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|  c|\n",
      "+---+\n",
      "|  1|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "events = jsonToDataFrame(\"\"\"\n",
    "{\n",
    "  \"a\": \"{\\\\\"b\\\\\":1}\"\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "events.select(json_tuple(\"a\", \"b\").alias(\"c\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Parse a well formed string column</b> - `regexp_extract()` can be used to parse strings using regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|  c|\n",
      "+---+\n",
      "|  x|\n",
      "|  y|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "events = jsonToDataFrame(\"\"\"\n",
    "[{ \"a\": \"x: 1\" }, { \"a\": \"y: 2\" }]\n",
    "\"\"\")\n",
    "\n",
    "events.select(regexp_extract(\"a\", \"([a-z]):\", 1).alias(\"c\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "name": "Transforming Complex Data Types - Python",
  "notebookId": 3724404464617467
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
